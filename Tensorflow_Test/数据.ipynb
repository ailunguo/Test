{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VZqz4qwBqPCB75JlC0lYM567au0NB8nL",
      "authorship_tag": "ABX9TyPXN2WepbCJbnsn9lfabydF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailunguo/Test/blob/main/Tensorflow_Test/%E6%95%B0%E6%8D%AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 图片数据加载"
      ],
      "metadata": {
        "id": "G_D6pW3LGZbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ROJGoOYMGgO1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "image_dataset_from_directory函数"
      ],
      "metadata": {
        "id": "EJd_W2mHHL_w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Isi4cH3GRpL"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.image_dataset_from_directory(\n",
        "    directory,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(256, 256),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,\n",
        "    **kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 其中directory为存储本地图片的文件\n",
        "# 结构为\n",
        "# main_directory/\n",
        "# ...class_a/\n",
        "# ......a_image_1.jpg\n",
        "# ......a_image_2.jpg\n",
        "# ...class_b/\n",
        "# ......b_image_1.jpg\n",
        "# ......b_image_2.jpg\n",
        "# 得到一个tf.data.Dataset其中class_a为0，class_b为1"
      ],
      "metadata": {
        "id": "b8kTTPGzGjgf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load_img函数"
      ],
      "metadata": {
        "id": "IbdoKz66HOcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.load_img(\n",
        "    path,\n",
        "    grayscale=False,\n",
        "    color_mode=\"rgb\",\n",
        "    target_size=None,\n",
        "    interpolation=\"nearest\",\n",
        "    keep_aspect_ratio=False,\n",
        ")"
      ],
      "metadata": {
        "id": "5PeMhaVzHF75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 将图片加载为PIL模式\n",
        "image = tf.keras.utils.load_img(image_path)\n",
        "input_arr = tf.keras.img_to_array(image)\n",
        "input_arr = np.array([input_arr])\n",
        "predictions = model.predict(input_arr)"
      ],
      "metadata": {
        "id": "g_G48DmfHSz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "image_to_array函数"
      ],
      "metadata": {
        "id": "3ALQWdSvH3XR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.img_to_array(img, data_format=None, dtype=None)"
      ],
      "metadata": {
        "id": "LtsgroBtH6PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 将PIL图像转换为Numpy数组\n",
        "from PIL import Image\n",
        "img_data = np.random.random(size=(100, 100, 3))\n",
        "img = tf.keras.utils.array_to_img(img_data)\n",
        "array = tf.keras.utils.image.img_to_array(img)"
      ],
      "metadata": {
        "id": "l7SZNXrSH78T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "save_img函数"
      ],
      "metadata": {
        "id": "0eehJS5XIeAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.save_img(\n",
        "    path, x, data_format=None, file_format=None, scale=True, **kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "patpxldIIdjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 时序数据加载"
      ],
      "metadata": {
        "id": "CBAEIcWOJRKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "timeseries_dataset_from_array函数"
      ],
      "metadata": {
        "id": "CC5iriEAJWJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.timeseries_dataset_from_array(\n",
        "    data,\n",
        "    targets,\n",
        "    sequence_length,\n",
        "    sequence_stride=1,\n",
        "    sampling_rate=1,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        "    seed=None,\n",
        "    start_index=None,\n",
        "    end_index=None,\n",
        ")"
      ],
      "metadata": {
        "id": "aOAA6GkOIiL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 考虑指数[0, 1, ... 98]。\n",
        "# 使用sequence_length=10, sampling_rate=2, sequence_stride=3, shuffle=False，\n",
        "# 数据集将产生由以下索引组成的批次序列：\n",
        "# First sequence:  [0  2  4  6  8 10 12 14 16 18]\n",
        "# Second sequence: [3  5  7  9 11 13 15 17 19 21]\n",
        "# Third sequence:  [6  8 10 12 14 16 18 20 22 24]\n",
        "# ...\n",
        "# Last sequence:   [78 80 82 84 86 88 90 92 94 96]"
      ],
      "metadata": {
        "id": "EVIW4OtpJZPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 时间回归\n",
        "input_data = data[:-10]\n",
        "targets = data[10:]\n",
        "dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    input_data, targets, sequence_length=10)\n",
        "for batch in dataset:\n",
        "  inputs, targets = batch\n",
        "  assert np.array_equal(inputs[0], data[:10])\n",
        "  assert np.array_equal(targets[0], data[10])\n",
        "  break"
      ],
      "metadata": {
        "id": "DOHj-BGwJ5NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 多对多架构的时间回归\n",
        "X = np.arange(100)\n",
        "Y = X*2\n",
        "\n",
        "sample_length = 20\n",
        "input_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    X, None, sequence_length=sample_length, sequence_stride=sample_length)\n",
        "target_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    Y, None, sequence_length=sample_length, sequence_stride=sample_length)\n",
        "\n",
        "for batch in zip(input_dataset, target_dataset):\n",
        "  inputs, targets = batch\n",
        "  assert np.array_equal(inputs[0], X[:sample_length])\n",
        "\n",
        "  assert np.array_equal(targets[1], Y[sample_length:2*sample_length])\n",
        "  break"
      ],
      "metadata": {
        "id": "PIZSRt1cLTrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 文本数据加载"
      ],
      "metadata": {
        "id": "ISV-zxEROBKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "text_dataset_from_directory函数"
      ],
      "metadata": {
        "id": "YPrkG1KDOG6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.text_dataset_from_directory(\n",
        "    directory,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    class_names=None,\n",
        "    batch_size=32,\n",
        "    max_length=None,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    follow_links=False,\n",
        ")"
      ],
      "metadata": {
        "id": "qVdY5eMUN_kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 上述directory是文本数据保存的目录，目录结构应该是下面的样子\n",
        "# main_directory/\n",
        "# ...class_a/\n",
        "# ......a_text_1.txt\n",
        "# ......a_text_2.txt\n",
        "# ...class_b/\n",
        "# ......b_text_1.txt\n",
        "# ......b_text_2.txt"
      ],
      "metadata": {
        "id": "oUZ5EBtPOJRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 音频数据加载"
      ],
      "metadata": {
        "id": "Z3gR8ujzOn-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "audio_dataset_from_directory函数"
      ],
      "metadata": {
        "id": "5JkLkTWeOrnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.audio_dataset_from_directory(\n",
        "    directory,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    class_names=None,\n",
        "    batch_size=32,\n",
        "    sampling_rate=None,\n",
        "    output_sequence_length=None,\n",
        "    ragged=False,\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    follow_links=False,\n",
        ")"
      ],
      "metadata": {
        "id": "4kvDHSQkOk-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# directory是存放音频数据的目录，目录结构如下\n",
        "# main_directory/\n",
        "# ...class_a/\n",
        "# ......a_audio_1.wav\n",
        "# ......a_audio_2.wav\n",
        "# ...class_b/\n",
        "# ......b_audio_1.wav\n",
        "# ......b_audio_2.wav"
      ],
      "metadata": {
        "id": "vtTSgXdHOvTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 内置的小数据集"
      ],
      "metadata": {
        "id": "i_WEvb8AO_E3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST数字分类数据集\n",
        "\n",
        "这是一个包含 60,000 张 10 位数字的 28x28 灰度图像的数据集，以及一个包含 10,000 张图像的测试集\n",
        "\n",
        "更多信息在这儿找http://yann.lecun.com/exdb/mnist/"
      ],
      "metadata": {
        "id": "KYCCdQXPPSus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")"
      ],
      "metadata": {
        "id": "x7yv0ww8PEJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "assert x_train.shape == (60000, 28, 28)\n",
        "assert x_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)"
      ],
      "metadata": {
        "id": "MquwdXJVPrby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR10小图像分类数据集\n",
        "\n",
        "这是一个包含 50,000 张 32x32 彩色训练图像和 10,000 张测试图像的数据集，标记了 10 多个类别\n",
        "\n",
        "更多信息https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "metadata": {
        "id": "7lageT7dQFAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "飞机，汽车，鸟，猫，鹿，狗，青蛙，马，船，卡车"
      ],
      "metadata": {
        "id": "jkPzT3A1QJro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "assert x_train.shape == (50000, 32, 32, 3)\n",
        "assert x_test.shape == (10000, 32, 32, 3)\n",
        "assert y_train.shape == (50000, 1)\n",
        "assert y_test.shape == (10000, 1)"
      ],
      "metadata": {
        "id": "xiaj2zVuQJUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR100小图像分类数据集\n",
        "\n",
        "这是一个包含 50,000 张 32x32 颜色训练图像和 10,000 张测试图像的数据集，标记了 100 多个细粒度类，这些细粒度类又分为 20 个粗粒度类\n",
        "\n",
        "更多信息https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "metadata": {
        "id": "u76UNibPQ8L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.dataset.cirfar100.load()\n",
        "assert x_train.shape == (50000, 32, 32, 3)\n",
        "assert x_test.shape == (10000, 32, 32, 3)\n",
        "assert y_train.shape == (50000, 1)\n",
        "assert y_test.shape == (10000, 1)"
      ],
      "metadata": {
        "id": "GZTKt-xCRHX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMDB电影评论情感分类数据集\n",
        "\n",
        "这是来自 IMDB 的 25,000 条电影评论的数据集，按情绪（正面/负面）标记。评论已经过预处理，每个评论都被编码为单词索引（整数）列表。为了方便起见，单词按数据集中的总体频率进行索引，例如整数“3”编码数据中第三个最常见的单词。这允许快速过滤操作，例如：“仅考虑前 10,000 个最常见的单词，但消除前 20 个最常见的单词”。\n",
        "\n",
        "按照惯例，“0”并不代表特定的单词，而是用于对填充令牌进行编码。"
      ],
      "metadata": {
        "id": "7zAx0LD_Rni6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.datasets.imdb.load_data(\n",
        "    path=\"imdb.npz\",\n",
        "    num_words=None,\n",
        "    skip_top=0,\n",
        "    maxlen=None,\n",
        "    seed=113,\n",
        "    start_char=1,\n",
        "    oov_char=2,\n",
        "    index_from=3,\n",
        "    **kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "-sKoc6RRRTyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.datasets.imdb.get_word_index(path=\"imdb_word_index.json\")"
      ],
      "metadata": {
        "id": "9lAa8CimSfsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_char = 1\n",
        "oov_char = 2\n",
        "index_from = 3\n",
        "(x_train, _), _ = keras.datasets.imdb.load_data(\n",
        "    start_char=start_char, oov_char=oov_char, index_from=index_from)\n",
        "word_index = keras.datasets.imdb.get_word_index()\n",
        "inverted_word_index = dict(\n",
        "    (i + index_from, word) for (word, i) in word_index.items())\n",
        "inverted_word_index[start_char] = \"[START]\"\n",
        "inverted_word_index[oov_char] = \"[OOV]\"\n",
        "decoded_sequence = \"\".join(inverted_word_index[i] for i in x_train[0])"
      ],
      "metadata": {
        "id": "g9tdzJqYSoG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "路透社新闻专线分类数据集\n",
        "\n",
        "这是来自路透社的 11,228 条新闻专线的数据集，标记了超过 46 个主题。每个新闻专线都被编码为单词索引（整数）列表。为了方便起见，单词按数据集中的总体频率进行索引，例如整数“3”编码数据中第三个最常见的单词。这允许快速过滤操作，例如：“仅考虑前 10,000 个最常见的单词，但消除前 20 个最常见的单词”。"
      ],
      "metadata": {
        "id": "unRHjflYVGET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.datasets.reuters.load_data(\n",
        "    path=\"reuters.npz\",\n",
        "    num_words=None,\n",
        "    skip_top=0,\n",
        "    maxlen=None,\n",
        "    test_split=0.2,\n",
        "    seed=113,\n",
        "    start_char=1,\n",
        "    oov_char=2,\n",
        "    index_from=3,\n",
        "    **kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "HySYBQvdVKCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.datasets.reuters.get_word_index(path=\"reuters_word_index.json\")"
      ],
      "metadata": {
        "id": "UoHsUDKoVd7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "时尚MNIST数据集，MNIST的替代品\n",
        "\n",
        "同样包含10类数据集，但这10类是相关的时尚商品的灰度图片"
      ],
      "metadata": {
        "id": "1Gtb8Qz0ViCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "MpK2k4UWVm5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "assert x_train.shape == (60000, 28, 28)\n",
        "assert x_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)"
      ],
      "metadata": {
        "id": "-r5RTx8sVyET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "波士顿房价回归数据集"
      ],
      "metadata": {
        "id": "XMZsJ7YWV0uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.datasets.boston_housing.load_data(\n",
        "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
        ")"
      ],
      "metadata": {
        "id": "vSATIhIZV2HM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JOq-rPZgV3XO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(weights='imagenet')\n",
        "\n",
        "img_path = '/content/drive/MyDrive/zhihui/cat_2.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsjwPLqjXHvG",
        "outputId": "8b7b157a-c423-4745-cefc-afca664eb670"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "35363/35363 [==============================] - 0s 0us/step\n",
            "Predicted: [('n02127052', 'lynx', 0.3872096), ('n02119789', 'kit_fox', 0.12989666), ('n02123159', 'tiger_cat', 0.09972875)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J3OBq8jvX7q1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}