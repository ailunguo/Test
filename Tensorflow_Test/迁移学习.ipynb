{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMG7bPB4rBuLofUosr8LNwn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailunguo/Test/blob/main/Tensorflow_Test/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "常见的迁移学习的工作流程\n",
        "\n",
        "1，从先前的训练模型中获取图层\n",
        "\n",
        "2，冻结它们，以避免在以后的训练中破坏它们包含的任何信息\n",
        "\n",
        "3，在冻结层之上添加一些新的可训练层，它们将学习将旧特征转化为对新数据集的预测\n",
        "\n",
        "4，在数据集上训练新图层\n",
        "\n",
        "最后一个步骤就是微调，其中包括解冻上面获得的整个模型(或部分模型),并以非常低的学习率在新数据上重新训练它。通过逐步使预训练的特征适应新数据，这可能会实现有意义的改进。"
      ],
      "metadata": {
        "id": "-EOK0G6wr7QO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vAQhOyebrkl_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 冻结层: 理解trainable属性"
      ],
      "metadata": {
        "id": "YzfE7I8itF9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "图层和模型具有三个权重属性：\n",
        "\n",
        "weights是该层所有权重变量的列表。\n",
        "\n",
        "trainable_weights是要更新（通过梯度下降）以最小化训练期间损失的列表。\n",
        "\n",
        "non_trainable_weights是那些不应该接受培训的人员的列表。通常，它们由模型在前向传播期间更新。"
      ],
      "metadata": {
        "id": "XXvdaMiXtPvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 该Dense有两个可训练的权重(内核和偏差)\n",
        "layer = keras.layers.Dense(3)\n",
        "layer.build((None, 4))\n",
        "\n",
        "print('weights:', len(layer.weights))\n",
        "print('trainable_weights:', len(layer.trainable_weights))\n",
        "print('non_trainable_weights:', len(layer.non_trainable_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wCZoDVarz_H",
        "outputId": "56d7e752-cb4d-4352-e331-4902def1c812"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights: 2\n",
            "trainable_weights: 2\n",
            "non_trainable_weights: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 该BatchNormalization层有 2 个可训练权重和 2 个不可训练权重\n",
        "layer = keras.layers.BatchNormalization()\n",
        "layer.build((None, 4))  # Create the weights\n",
        "\n",
        "print(\"weights:\", len(layer.weights))\n",
        "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
        "print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D34f59XDt03Y",
        "outputId": "5d258e9f-b14b-4fc3-937e-2de3f81ac499"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights: 4\n",
            "trainable_weights: 2\n",
            "non_trainable_weights: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置trainable为False\n",
        "layer = keras.layers.Dense(3)\n",
        "layer.build((None, 4))  # Create the weights\n",
        "layer.trainable = False  # Freeze the layer\n",
        "\n",
        "print(\"weights:\", len(layer.weights))\n",
        "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
        "print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rrct6EPluHCo",
        "outputId": "d234117b-e647-4918-f9f6-39f63fb46b01"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights: 2\n",
            "trainable_weights: 0\n",
            "non_trainable_weights: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "当可训练权重变为不可训练权重时，其值在训练期间不再更新。"
      ],
      "metadata": {
        "id": "Q3rV_xsuvRyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer1 = keras.layers.Dense(3, activation='relu')\n",
        "layer2 = keras.layers.Dense(3, activation='sigmoid')\n",
        "model = keras.Sequential([keras.Input(shape=(3,)), layer1, layer2])\n",
        "\n",
        "# 将layer1层冻结\n",
        "layer1.trainable = False\n",
        "\n",
        "# 将layer1的权重复制一下\n",
        "initial_layer1_weights_values = layer1.get_weights()\n",
        "\n",
        "# 训练模型\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "\n",
        "final_layer1_weights_values = layer1.get_weights()\n",
        "np.testing.assert_allclose(\n",
        "    initial_layer1_weights_values[0], final_layer1_weights_values[0]\n",
        ")\n",
        "np.testing.assert_allclose(\n",
        "    initial_layer1_weights_values[1], final_layer1_weights_values[1]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBOQjEOzvPNR",
        "outputId": "445630e7-210d-4d33-c8d1-b415a5635c6e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 503ms/step - loss: 0.1272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trainable属性的递归设置\n",
        "\n",
        "如果您trainable = False在模型或任何具有子层的层上进行设置，则所有子层也将变得不可训练。"
      ],
      "metadata": {
        "id": "nXImNj8vw5l8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inner_model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(3,)),\n",
        "        keras.layers.Dense(3, activation='relu'),\n",
        "        keras.layers.Dense(3, activation='relu'),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(3,)),\n",
        "        inner_model,\n",
        "        keras.layers.Dense(3, activation='sigmoid'),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.trainable = False  # 将整个模型的trainable设置为False\n",
        "\n",
        "assert inner_model.trainable == False # 所有模型都被冻结\n",
        "assert inner_model.layers[0].trainable == False # 'trainable'是具有递归性质的"
      ],
      "metadata": {
        "id": "tEQgN_TWw1Q5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras迁移学习流程"
      ],
      "metadata": {
        "id": "bekNPMAXzxAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用预先训练的权重实例化基本模型"
      ],
      "metadata": {
        "id": "KK8DfmZVz0s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.Xception(\n",
        "    weights = 'imagenet',\n",
        "    input_shape = (150, 150, 3),\n",
        "    include_top = False\n",
        ")\n",
        "\n",
        "# 然后冻结该基本模型\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q13Fro6cx1DZ",
        "outputId": "04f5c434-71b2-4979-c8a3-e4feb612983f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "在此基础上创建一个新的模型"
      ],
      "metadata": {
        "id": "FO6_lFNg1KQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 在基本模型之上创建一个新的模型\n",
        "inputs = keras.Input(shape=(150, 150, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x) # 一个新的全局平均池化层\n",
        "outputs = keras.layers.Dense(1)(x)  # 最后输出层输出一个\n",
        "model = keras.Model(inputs, outputs) # 这是个新的模型"
      ],
      "metadata": {
        "id": "kOn83UP70O92"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用新模型训练数据"
      ],
      "metadata": {
        "id": "_aHoQjzZ1QPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "       loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "       metrics=[keras.metrics.BinaryAccuracy()])\n",
        "# 选择是否设置from_logits参数通常取决于模型的最后一层以及任务的特性。\n",
        "# 如果模型的最后一层包含sigmoid激活函数，并输出概率值（范围在0到1之间），\n",
        "# 则通常将from_logits设置为False。如果最后一层输出未经处理的 logits，\n",
        "# 通常将from_logits设置为 True，以确保在计算损失时应用适当的转换。\n",
        "\n",
        "model.fit(new_dataset, epochs=20, callbacks=..., validation_data=...)"
      ],
      "metadata": {
        "id": "fHc00TKE09Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 微调"
      ],
      "metadata": {
        "id": "uUgqmMcV2rRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1，一旦您的模型收敛于新数据，您可以尝试解冻全部或部分基础模型，并以非常低的学习率端到端地重新训练整个模型。\n",
        "\n",
        "2，这是可选的最后一步，可能会给您带来增量改进。***它还可能导致快速过度拟合***\n",
        "\n",
        "3，**只有在具有冻结层的模型经过训练以收敛之后才执行此步骤**\n",
        "\n",
        "4，在此阶段使用***非常低的学习率***也很重要，因为您要在通常*非常小的数据集上训练比第一轮训练大得多的模型*。"
      ],
      "metadata": {
        "id": "vJbCnYOX2zw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 解冻基础模型\n",
        "# 还要再重新编译解冻后的模型\n",
        "base_model.trainable = True\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-5),\n",
        "       loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "       metrics=[keras.metrics.BinaryAccuracy()])\n",
        "model.fit(new_dataset, epochs=10, callbacks=..., validation_data=...)"
      ],
      "metadata": {
        "id": "3Hv1PoZ42sPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "如果您更改任何trainable值，请确保compile()再次调用您的模型以使更改生效。"
      ],
      "metadata": {
        "id": "Sni0iiav4VnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "mluyUhJa4aOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 通过自定义训练循环进行迁移学习和微调"
      ],
      "metadata": {
        "id": "WZGFNCdz5QAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建基础模型\n",
        "base_model = keras.applications.Xception(\n",
        "    weights = 'imagenet',\n",
        "    input_shape = (150, 150, 3),\n",
        "    include_top = False\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = keras.Input(shape=(150, 150, 3))\n",
        "x = base_model(inputs, training=False) # training=False告诉call方法，无论是训练还是推理都不更新权重\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "outputs = keras.layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "optimizer = keras.optimizers.Adam()\n",
        "\n",
        "for inputs, targets in new_dataset:\n",
        "  with tf.GradientTape() as tape:\n",
        "    pred = model(inputs)\n",
        "    loss_val = loss_fn(targets, pred)\n",
        "\n",
        "  gradients = tape.gradient(loss_val, model.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(gradiens, model.trainable_weights))"
      ],
      "metadata": {
        "id": "z7KuNvHJ4YrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZvDNvXl778oH"
      }
    }
  ]
}