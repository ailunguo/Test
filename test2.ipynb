{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4flIqDvpv6Pl2n/3EaMuK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailunguo/Test/blob/main/test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oPHTRPkb3KkM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import CenterCrop\n",
        "from tensorflow.keras.layers import Rescaling"
      ],
      "metadata": {
        "id": "bcnH4RhS3ePs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "BTILhQdB3gKl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(keras.Model):\n",
        "  def train_step(self, data):\n",
        "    x, y = data\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = self(x, training=True)\n",
        "      loss = self.compute_loss(y=y, y_pred=y_pred)\n",
        "    trainable_vars = self.trainable_variables\n",
        "    gradients = tape.gradient(loss, trainable_vars)\n",
        "    self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "    for metric in self.metrics:\n",
        "      if metric.name == 'loss':\n",
        "        metric.update_state(loss)\n",
        "      else:\n",
        "        metric.update_state(y, y_pred)\n",
        "    return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "inputs = keras.Input(shape=(32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "model = CustomModel(inputs, outputs)\n",
        "model.compile(optimizer='adam', loss='mse', metrics=[...])\n",
        "\n",
        "model.fit(dataset, epochs=3, callbacks=...)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "rN7kh_IB3n19",
        "outputId": "e1936c2a-a010-48e5-87b5-044ce1cb09ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9bd3308d73f0>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 使用多个GPU加速训练"
      ],
      "metadata": {
        "id": "LULkvoCa_ZAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "  model = Model()\n",
        "  model.compile()\n",
        "\n",
        "trian_dataset, val_dataset, test_dataset = get_dataset()\n",
        "model.fit(train_dataset, epochs=2, validation_data=val_dataset)\n",
        "\n",
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "wLer7Kab_chV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 在设备上同步进行预处理与在主机CPU上异步进行预处理"
      ],
      "metadata": {
        "id": "Q7ajQxQOCIvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 在CPU上进行异步操作, 只需将dataset.map预处理操作注入到数据管道中"
      ],
      "metadata": {
        "id": "egs9Nhf0HvN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.src.layers.preprocessing.text_vectorization import TextVectorization\n",
        "samples = np.array([['This is the 1st sample.'], [\"And here's the 2nd sample.\"]])\n",
        "labels = [[0], [1]]\n",
        "\n",
        "vectorizer = TextVectorization(output_mode='int')\n",
        "vectorizer.adapt(samples)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((samples, labels)).batch(2)\n",
        "\n",
        "dataset = dataset.map(lambda x, y: (vectorizer(x), y))\n",
        "\n",
        "dataset = dataset.prefetch(2)\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype='int64')\n",
        "x = layers.Embedding(input_dim=10, output_dim=32)(inputs)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', run_eagerly=True)\n",
        "model.fit(dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TolnzIiRCHwV",
        "outputId": "9634cb69-71cc-41c7-a3cd-5df60ac96433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 309ms/step - loss: 0.5282\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d45b3b9c790>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((samples, labels)).batch(2)\n",
        "\n",
        "inputs = keras.Input(shape=(1,), dtype='string')\n",
        "x = vectorizer(inputs)\n",
        "x = layers.Embedding(input_dim=10, output_dim=32)(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', run_eagerly=True)\n",
        "model.fit(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn_-PDw5CnVF",
        "outputId": "67e73883-7a2a-4b9f-bd2c-f99e5435becd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 444ms/step - loss: 0.5138\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d45b3a69960>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 通过超参数调整找到最佳模型"
      ],
      "metadata": {
        "id": "Ege29tbOH-os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 首先，将模型定义放入一个带有单个hp参数的函数中。在此函数内，用对超参数采样方法的\n",
        "# 调用替换要调整的任何值，例如hp.Int() or hp.Choice()\n",
        "\n",
        "def build_model(hp):\n",
        "  inputs = keras.Input(shape=(784,))\n",
        "  x = layers.Dense(\n",
        "      units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
        "      activation='relu')(inputs)\n",
        "  outputs = layers.Dense(10, activation='softmax')(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(\n",
        "          hp.Choice('learning_rate',\n",
        "               values=[1e-2, 1e-3, 1e-4])),\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "b0E8sUf1E1MN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 接下来实例化一个调谐器对象，指定优化目标和其他搜索参数\n",
        "import keras_tuner\n",
        "\n",
        "tuner = keras_tuner.tuners.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_epochs=100,\n",
        "    factor=3,\n",
        "    directory='my_dir')\n"
      ],
      "metadata": {
        "id": "3b-rXiGJJvRV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(64)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcfsNsoQKyj_",
        "outputId": "bd199bf7-d95e-44d7-d0d1-4f73ddc2d49d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1gDJExDmLpel"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qB_uhUI2PE_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}