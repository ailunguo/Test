{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5jFGN4F/M7srJlcDdudSM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailunguo/Test/blob/main/My_Test/my_test_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VdX3bGap_Yyv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC_LyFmp_dMK",
        "outputId": "6609615b-7693-42b9-8a1b-bdd64cd528e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-b7QrDmASXk",
        "outputId": "2d00c224-aad8-4237-b740-0c08f3e1d183"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([[20., 30., 40., 80.],\n",
        "          [20., 30., 40., 80.]], dtype=tf.float32)\n",
        "print(a)\n",
        "b = tf.keras.layers.Rescaling(1.0 / 4)(a)\n",
        "c = tf.keras.layers.Flatten()(b)\n",
        "print(c)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACBtDf1aAyn6",
        "outputId": "c8ad8ac8-bc13-45e7-86c9-fc0272e61178"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[20. 30. 40. 80.]\n",
            " [20. 30. 40. 80.]], shape=(2, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 5.   7.5 10.  20. ]\n",
            " [ 5.   7.5 10.  20. ]], shape=(2, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(28, 28)) # 输入层\n",
        "\n",
        "# 将像素值缩放到0-1之间\n",
        "x = tf.keras.layers.Rescaling(1.0 / 255)(inputs)\n",
        "\n",
        "# 把shape=(28, 28)的展开\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "# 添加层，激活函数为relu\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "# 最后加一个softmax层\n",
        "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# 结合inputs, outputs生成模型\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 通过summary()得到网络的详细结构\n",
        "model.summary()\n",
        "\n",
        "# 模型组合好后就是编译了\n",
        "# 在编译中，添加损失函数和优化器\n",
        "# 损失函数用来计算损失并为计算梯度做准备\n",
        "# 然后通过优化器来更新权重\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# 接下来就是训练模型了\n",
        "# 这里需要声明训练的轮数及epochs的值\n",
        "# 以及定义batch_size大小来把大的数据集分成多个batch\n",
        "# 及更新一次权重需要训练一个batch_size\n",
        "batch_size = 64\n",
        "print(\"Fit on Numpy data\")\n",
        "# 先用numpy类型的数据，训练一个epoch\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=1)\n",
        "\n",
        "# 再用dataset集合来训练一个epoch\n",
        "# 生成dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
        "print(\"Fit on Dataset\")\n",
        "model.fit(dataset, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsQVVv5EAUpy",
        "outputId": "18c7207f-1043-4533-b35c-5d334052bb07"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 28, 28)]          0         \n",
            "                                                                 \n",
            " rescaling_19 (Rescaling)    (None, 28, 28)            0         \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118282 (462.04 KB)\n",
            "Trainable params: 118282 (462.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Fit on Numpy data\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.2648\n",
            "Fit on Dataset\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.1169\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f48184123e0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 上述训练中我们把训练过程赋给了一个history变量\n",
        "# history.history返回训练之后得到的各个指标的值\n",
        "print(history.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrak6sa6GHCM",
        "outputId": "1356f400-a53f-4756-9311-f68be9a1464b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': [0.2648496627807617]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 上述训练过程中我们只看的loss这个指标值，我们还可以增加显示的指标值\n",
        "# 注，我们还可以再次编译训练之后的模型，因为训练之后的模型只不过是权重变了，其他的和最初的模型没啥区别\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name='acc')],\n",
        ")\n",
        "history = model.fit(dataset, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faXjv85-KX89",
        "outputId": "d13403f2-dc6d-4af1-9642-3eb220cff458"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "938/938 [==============================] - 5s 4ms/step - loss: 0.0804 - acc: 0.9754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 我们还可以将验证集传入来观察模型在验证集上的指标\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
        "model.fit(dataset, epochs=1, validation_data=val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37awoUgHL1pG",
        "outputId": "b2c6201b-b4fd-4900-8399-03e1dd9e65b9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0557 - acc: 0.9830 - val_loss: 0.0883 - val_acc: 0.9753\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f481aef1cf0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 好了上述我们用了训练集和验证集，同时让模型在训练的时候显示一些指标\n",
        "# 但是，问题还远远没有结束，想想还有什么问题，其实到这里我们已经学会训练神经网络了\n",
        "# 但但但但但是，如果我们在训练的时候遇到了停电，等突然使训练中断怎么办\n",
        "# 也许你会说，再重新开始训练呗，。。。。。。，如果你已经训练了好几天了，这时候你有什么想法\n",
        "# 去死吧。。。。。。\n",
        "# 大型的神经网络训练一般时间是按小时或者天来计算，这时保存已经训练的模型非常重要\n",
        "# 通过回调模型来设置什么时候保存，如一个batch后，一个epochs后\n",
        "# 将这个回调模型放在fit()中\n",
        "\n",
        "\n",
        "# callbacks = [\n",
        "#     keras.callbacks.ModelCheckpoint(\n",
        "#         filepath='path',\n",
        "#         save_freq='epoch'\n",
        "#     )\n",
        "# ]\n",
        "# model.fit(dataset, epochs=2, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "MNnSLZVlMnEV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tFXxhqCyPQoW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}